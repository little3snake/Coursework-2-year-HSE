# Coursework-2-year-HSE
A part of the coursework with PPO implementations: https://github.com/little3snake/RL_PPO_algorithm/tree/main
## Folders:
#### CartPole
Environment:CartPole-v1
Algorythm: DQN
PyTorch
#### LunarLander_PT
Environment: LunarLander-v3
Algorythm: DQN
PyTorch
#### LunarLander_SB
Environment: LunarLander-v3
Algorythm: DQN
Stable-Baselines3
#### BipedalWalker_ppo_SB
Environment: BipedalWalker-v3
Algorythm: PPO
Stable-Baselines3
#### BipedalWalker_ppo_PT
Environment: BipedalWalker-v3
Algorythm: PPO
PyTorch
